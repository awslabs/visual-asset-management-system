# VAMS v2.1 to v2.2 Data Migration

This document provides instructions for running the data migration script to migrate from VAMS v2.1 to v2.2.

Note: RUN THIS AFTER YOUR CDK DEPLOYMENT OF V2.2

## Migration Overview

The migration script performs the following operations:

1. **Asset Versions Migration**:

    - For each record in the assets table, create a record in the new asset versions table
    - Map fields from the `currentVersion` field in the assets table to the new structure in the asset versions table

2. **Asset Records Update**:

    - Update the `assetLocation` field structure: `{'assetLocation': { 'Key': "{baseAssetsPrefix}{assetId}/" }}`
    - Add `bucketId` to each asset record based on lookup from S3_Asset_Buckets table
    - Move the version number from `currentVersion.Version` to a new field `currentVersionId`
    - Remove specified fields: `isMultiFile`, `pipelineId`, `executionId`, `versions`, `currentVersion`, `specifiedPipelines`, `Parent`, `objectFamily`

3. **Database Records Update**:
    - Add `defaultBucketId` to all records in the databases table

## Prerequisites

1. Python 3.6 or higher
2. AWS SDK for Python (boto3)
3. AWS credentials with permissions to read and write to the DynamoDB tables
4. AWS profile configured with the necessary permissions

## Installation

1. Install the required Python packages:

```bash
pip install boto3
```

2. Configure your AWS credentials:

```bash
aws configure --profile your-profile-name
```

## Configuration

Before running the script, you need to configure the table names, asset bucket name, and base assets prefix. You can do this in several ways:

### Option 1: Use a Configuration File (Recommended)

A sample configuration file `v2.1_to_v2.2_migration_config.json` is provided. Copy this file and modify it with your specific values:

```json
{
    "assets_table_name": "YOUR_ASSETS_TABLE_NAME",
    "asset_versions_table_name": "YOUR_ASSET_VERSIONS_TABLE_NAME",
    "s3_asset_buckets_table_name": "YOUR_S3_ASSET_BUCKETS_TABLE_NAME",
    "databases_table_name": "YOUR_DATABASES_TABLE_NAME",
    "base_assets_prefix": "YOUR_BASE_ASSETS_PREFIX",
    "asset_bucket_name": "YOUR_ASSET_BUCKET_NAME",
    "aws_profile": "YOUR_AWS_PROFILE",
    "aws_region": "YOUR_AWS_REGION",
    "log_level": "INFO",
    "batch_size": 25,
    "dry_run": false
}
```

Then run the script with the `--config` option:

```bash
python v2.1_to_v2.2_migration.py --config your_config_file.json
```

### Option 2: Edit the Configuration in the Script

Open the script and modify the `CONFIG` dictionary at the top of the file:

```python
CONFIG = {
    # Source tables
    "assets_table_name": "YOUR_ASSETS_TABLE_NAME",
    "asset_versions_table_name": "YOUR_ASSET_VERSIONS_TABLE_NAME",
    "s3_asset_buckets_table_name": "YOUR_S3_ASSET_BUCKETS_TABLE_NAME",
    "databases_table_name": "YOUR_DATABASES_TABLE_NAME",

    # Asset configuration
    "base_assets_prefix": "YOUR_BASE_ASSETS_PREFIX",
    "asset_bucket_name": "YOUR_ASSET_BUCKET_NAME",

    # AWS settings
    "aws_profile": None,
    "aws_region": None,

    # Migration settings
    "log_level": "INFO",
    "batch_size": 25,
    "dry_run": False
}
```

### Option 3: Provide Configuration via Command Line Arguments

You can also provide the configuration via command line arguments when running the script:

```bash
python v2.1_to_v2.2_migration.py \
  --profile your-aws-profile \
  --region us-east-1 \
  --assets-table YourAssetsTableName \
  --asset-versions-table YourAssetVersionsTableName \
  --s3-asset-buckets-table YourS3AssetBucketsTableName \
  --databases-table YourDatabasesTableName \
  --base-assets-prefix assets/ \
  --asset-bucket-name your-assets-bucket
```

## Running the Migration

### Using the Helper Scripts (Recommended)

Helper scripts are provided to simplify running the migration. These scripts will:

1. Run the migration using a configuration file
2. Save logs to a timestamped file
3. Optionally run the verification script after the migration

#### For Linux/macOS Users (Bash)

To use the shell script:

1. Make sure the script is executable:

```bash
chmod +x run_migration.sh
```

2. Run the script with an optional configuration file:

```bash
./run_migration.sh [config_file]
```

#### For Windows Users (PowerShell)

To use the PowerShell script:

```powershell
.\run_migration.ps1 [config_file]
```

If no configuration file is provided, the scripts will use `v2.1_to_v2.2_migration_config.json` by default.

### Running the Python Script Directly

If you prefer to run the Python script directly:

1. Make sure you have the correct AWS profile configured with permissions to access the DynamoDB tables.

2. Run the script with your AWS profile:

```bash
python v2.1_to_v2.2_migration.py --profile your-aws-profile
```

### Additional Options

-   `--config`: Path to a JSON configuration file
-   `--dry-run`: Perform a dry run without making any changes to the tables
-   `--limit N`: Process only N assets (useful for testing)
-   `--region`: Specify the AWS region (defaults to the region in your AWS profile)
-   `--log-level`: Set the logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
-   `--batch-size`: Number of items to process in each batch
-   `--asset-bucket-name`: Name of the S3 bucket used for asset storage
-   `--base-assets-prefix`: Base prefix for asset locations (should end with a slash). The default in most cases to use for previous VAMS version upgrades is "/".

Examples:

```bash
# Using a configuration file
python v2.1_to_v2.2_migration.py --config your_config.json

# Using command line arguments
python v2.1_to_v2.2_migration.py \
  --profile your-aws-profile \
  --region us-east-1 \
  --dry-run \
  --limit 10 \
  --log-level INFO
```

### Configuration Files

Several configuration file templates are provided:

1. **v2.1_to_v2.2_migration_config.json**: Basic configuration template
2. **v2.1_to_v2.2_migration_prod_config.json**: Template for production migration

You can copy and modify these files to match your environment.

## Verifying the Migration

After running the migration, you should verify that it was successful. A verification script is provided to help you check the results:

```bash
python v2.1_to_v2.2_migration_verify.py \
  --profile your-aws-profile \
  --assets-table your-assets-table \
  --asset-versions-table your-asset-versions-table \
  --s3-asset-buckets-table your-s3-asset-buckets-table \
  --databases-table your-databases-table \
  --base-assets-prefix / \
  --asset-bucket-name your-assets-bucket
```

The verification script:

1. Checks that all assets have a corresponding version record
2. Verifies that asset records have been updated correctly with the new structure
3. Verifies that database records have been updated with defaultBucketId
4. Generates a report of the verification results

The report is saved to a CSV file in the `reports` directory, along with a JSON summary file. The report includes details of any errors found during verification.

Additional verification options:

-   `--config`: Path to configuration file (same as the migration script)
-   `--limit N`: Maximum number of assets to verify
-   `--output`: Path to output report file
-   `--log-level`: Set the logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)

## Manual Verification

In addition to using the verification script, you should also manually verify that:

1. New records have been created in the asset versions table
2. Asset records have been updated with the new structure
3. Database records have been updated with defaultBucketId
4. The application works correctly with the migrated data

## Troubleshooting

If you encounter any issues during the migration, check the following:

1. **AWS Permissions**: Ensure your AWS profile has the necessary permissions to read and write to the DynamoDB tables.

2. **Table Names**: Verify that the table names in the configuration are correct.

3. **Asset Bucket Name and Prefix**: Verify that the asset bucket name and base assets prefix are correct and match the values in the S3_Asset_Buckets table.

4. **Error Logs**: Check the error logs for details about any failures during the migration.

5. **Dry Run**: Run the script with the `--dry-run` flag to see what changes would be made without actually making them.

6. **Limit Processing**: Use the `--limit` option to process a small number of assets first to verify the migration works as expected.

## Rollback

There is no automatic rollback functionality in the script. If you need to roll back the migration, you will need to restore the tables from backups.

## Support

If you encounter any issues with the migration script, please contact the VAMS development team for assistance.
